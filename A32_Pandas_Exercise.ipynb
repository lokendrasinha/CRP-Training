{"cells":[{"cell_type":"markdown","source":["####Name : Lokendra J. Sinha\n","####Roll No : 32-A\n","####Branch : AIML\n","####Date : 27/06/2025"],"metadata":{"id":"fv3qhy3xBTNz"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"NxUpBpNAzYwd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751021563130,"user_tz":-330,"elapsed":1121,"user":{"displayName":"Lokendra Sinha","userId":"01157800664172874909"}},"outputId":"d6f15118-2569-4d65-8ece-b7a060cae7b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- Intermediate Pandas Exercise ---\n","Complete each task by writing the requested Pandas code.\n","------------------------------------\n","\n","--- Task 1: Basic Pandas Functions and Converting Arrays to DataFrames ---\n","0    10\n","1    20\n","2    30\n","3    40\n","4    50\n","dtype: int64\n","[[98 96 89 85]\n"," [30 60 85 16]\n"," [93 53 25 95]]\n","    A   B   C   D\n","0  98  96  89  85\n","1  30  60  85  16\n","2  93  53  25  95\n","    A   B   C   D\n","0  98  96  89  85\n","1  30  60  85  16\n","2  93  53  25  95\n","\n","--- Task 2: Synthetic Data Generation for Practice ---\n","\n","--- Task 3: Indexing and Slicing in DataFrames ---\n","   Region  Sales\n","0    West  136.0\n","1    East  612.0\n","2    East    NaN\n","3    East  116.0\n","4   South    NaN\n","..    ...    ...\n","95  South  366.0\n","96  South  741.0\n","97   East  861.0\n","98   East  920.0\n","99  North  904.0\n","\n","[100 rows x 2 columns]\n","         Date Region Product  Sales  Quantity\n","2  2023-03-07   East  Laptop    NaN       6.0\n","6  2023-02-27   East  Laptop  688.0       4.0\n","10 2023-02-16  South  Laptop  865.0       5.0\n","18 2023-01-29  South  Laptop  785.0       4.0\n","20 2023-01-27   East  Laptop  206.0       6.0\n","24 2023-02-04  North  Laptop  906.0       9.0\n","27 2023-02-03  North  Laptop  893.0       6.0\n","30 2023-02-14  South  Laptop  764.0      10.0\n","34 2023-02-23   East  Laptop    NaN       NaN\n","41 2023-02-16  South  Laptop    NaN       NaN\n","45 2023-01-16  North  Laptop  992.0       9.0\n","49 2023-01-04   West  Laptop  633.0       8.0\n","52 2023-01-06   East  Laptop  150.0       NaN\n","53 2023-03-15  South  Laptop  783.0      10.0\n","56 2023-01-07  North  Laptop  987.0       1.0\n","57 2023-03-18  North  Laptop  990.0       5.0\n","62 2023-04-02  South  Laptop  719.0       4.0\n","64 2023-02-12   West  Laptop  144.0       4.0\n","66 2023-01-01   East  Laptop  407.0      10.0\n","69 2023-04-05   West  Laptop  680.0       8.0\n","75 2023-02-19  North  Laptop  382.0       9.0\n","83 2023-03-30   West  Laptop  851.0       5.0\n","96 2023-03-02  South  Laptop  741.0       2.0\n","99 2023-01-16  North  Laptop  904.0      10.0\n","         Date Region   Product  Sales  Quantity\n","1  2023-01-16   East   Monitor  612.0       1.0\n","6  2023-02-27   East    Laptop  688.0       4.0\n","11 2023-04-09   East     Mouse  801.0       6.0\n","14 2023-03-31   East     Mouse  532.0       6.0\n","42 2023-01-25   East  Keyboard  774.0      10.0\n","50 2023-01-04   East     Mouse  832.0      10.0\n","54 2023-03-22   East  Keyboard  989.0       4.0\n","59 2023-03-12   East   Monitor  931.0       5.0\n","70 2023-03-16   East     Mouse  649.0       2.0\n","71 2023-02-08   East     Mouse  910.0       7.0\n","79 2023-03-26   East  Keyboard  821.0      10.0\n","81 2023-02-24   East     Mouse  621.0       6.0\n","82 2023-03-28   East  Keyboard  791.0       6.0\n","89 2023-04-03   East     Mouse  996.0       6.0\n","97 2023-02-14   East  Keyboard  861.0       9.0\n","98 2023-02-08   East     Mouse  920.0       6.0\n","136.0\n","\n","--- Task 4: Data Cleaning (Handling Missing Values) ---\n","Date        0\n","Region      0\n","Product     0\n","Sales       5\n","Quantity    3\n","dtype: int64\n","         Date Region   Product       Sales  Quantity\n","0  2023-03-11   West   Monitor  136.000000       4.0\n","1  2023-01-16   East   Monitor  612.000000       1.0\n","2  2023-03-07   East    Laptop  562.515789       6.0\n","3  2023-03-30   East     Mouse  116.000000       2.0\n","4  2023-02-02  South     Mouse  562.515789       8.0\n","..        ...    ...       ...         ...       ...\n","95 2023-02-13  South   Monitor  366.000000       6.0\n","96 2023-03-02  South    Laptop  741.000000       2.0\n","97 2023-02-14   East  Keyboard  861.000000       9.0\n","98 2023-02-08   East     Mouse  920.000000       6.0\n","99 2023-01-16  North    Laptop  904.000000      10.0\n","\n","[100 rows x 5 columns]\n","         Date Region   Product  Sales  Quantity\n","0  2023-03-11   West   Monitor  136.0       4.0\n","1  2023-01-16   East   Monitor  612.0       1.0\n","3  2023-03-30   East     Mouse  116.0       2.0\n","5  2023-03-28   East  Keyboard  334.0       3.0\n","6  2023-02-27   East    Laptop  688.0       4.0\n","..        ...    ...       ...    ...       ...\n","95 2023-02-13  South   Monitor  366.0       6.0\n","96 2023-03-02  South    Laptop  741.0       2.0\n","97 2023-02-14   East  Keyboard  861.0       9.0\n","98 2023-02-08   East     Mouse  920.0       6.0\n","99 2023-01-16  North    Laptop  904.0      10.0\n","\n","[94 rows x 5 columns]\n","\n","--- Task 5: Data Manipulation (Columns, Sorting, Grouping) ---\n","         Date Region   Product  Sales  Quantity  Total_Revenue\n","0  2023-03-11   West   Monitor  136.0       4.0          544.0\n","1  2023-01-16   East   Monitor  612.0       1.0          612.0\n","2  2023-03-07   East    Laptop    NaN       6.0            NaN\n","3  2023-03-30   East     Mouse  116.0       2.0          232.0\n","4  2023-02-02  South     Mouse    NaN       8.0            NaN\n","..        ...    ...       ...    ...       ...            ...\n","95 2023-02-13  South   Monitor  366.0       6.0         2196.0\n","96 2023-03-02  South    Laptop  741.0       2.0         1482.0\n","97 2023-02-14   East  Keyboard  861.0       9.0         7749.0\n","98 2023-02-08   East     Mouse  920.0       6.0         5520.0\n","99 2023-01-16  North    Laptop  904.0      10.0         9040.0\n","\n","[100 rows x 6 columns]\n","         Date Region   Product  Sales  Quantity  Total_Revenue\n","66 2023-01-01   East    Laptop  407.0      10.0         4070.0\n","50 2023-01-04   East     Mouse  832.0      10.0         8320.0\n","49 2023-01-04   West    Laptop  633.0       8.0         5064.0\n","22 2023-01-05  South     Mouse  557.0      10.0         5570.0\n","37 2023-01-06  North  Keyboard  870.0      10.0         8700.0\n","..        ...    ...       ...    ...       ...            ...\n","69 2023-04-05   West    Laptop  680.0       8.0         5440.0\n","61 2023-04-07  North   Monitor  401.0       8.0         3208.0\n","32 2023-04-07   West     Mouse  127.0      10.0         1270.0\n","12 2023-04-08   West  Keyboard  327.0       3.0          981.0\n","11 2023-04-09   East     Mouse  801.0       6.0         4806.0\n","\n","[100 rows x 6 columns]\n","          Sales  Quantity\n","Region                   \n","East    16831.0     186.0\n","North   14264.0     158.0\n","South   14425.0     167.0\n","West     7919.0      93.0\n","Product\n","Keyboard    540.846154\n","Laptop      689.047619\n","Monitor     564.388889\n","Mouse       491.600000\n","Name: Sales, dtype: float64\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2-2850834798.py:90: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  df4_2_filled['Sales'].fillna(df4_2_filled['Sales'].mean(), inplace=True)\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","print(\"--- Intermediate Pandas Exercise ---\")\n","print(\"Complete each task by writing the requested Pandas code.\")\n","print(\"------------------------------------\")\n","\n","# Task 1: Basic Pandas Functions and Converting Arrays to DataFrames\n","print(\"\\n--- Task 1: Basic Pandas Functions and Converting Arrays to DataFrames ---\")\n","# 1.1 Create a Pandas Series named 's1_1' from a list of numbers [10, 20, 30, 40, 50].\n","s1_1 = pd.Series([10, 20, 30, 40, 50])\n","print(s1_1)\n","# 1.2 Create a 3x4 NumPy array named 'np_array1_2' with random integers between 1 and 100.\n","np_array1_2 = np.random.randint(1, 101, size=(3, 4))\n","print(np_array1_2)\n","# 1.3 Convert 'np_array1_2' into a Pandas DataFrame named 'df1_3' with columns 'A', 'B', 'C', 'D'.\n","df1_3 = pd.DataFrame(np_array1_2, columns=['A','B','C','D'])\n","print(df1_3)\n","print(df1_3.head(3))\n","\n","# Your code for Task 1 here:\n","\n","\n","\n","# Task 2: Synthetic Data Generation for Practice\n","print(\"\\n--- Task 2: Synthetic Data Generation for Practice ---\")\n","# Create a DataFrame named 'df_sales' with 100 rows and the following columns:\n","# - 'Date': A range of dates from '2023-01-01' to '2023-04-09' (inclusive).\n","# - 'Region': Randomly chosen from ['East', 'West', 'North', 'South'].\n","# - 'Product': Randomly chosen from ['Laptop', 'Mouse', 'Keyboard', 'Monitor'].\n","# - 'Sales': Random integers between 100 and 1000.\n","# - 'Quantity': Random integers between 1 and 10.\n","# - Introduce 5 random NaN values in the 'Sales' column and 3 random NaN values in the 'Quantity' column.\n","\n","dates = pd.date_range(start='2023-01-01', end='2023-04-09', freq='D')\n","regions = ['East', 'West', 'North', 'South']\n","products = ['Laptop', 'Mouse', 'Keyboard', 'Monitor']\n","\n","df_sales = pd.DataFrame({\n","    'Date': np.random.choice(dates, 100, replace=True),\n","    'Region': np.random.choice(regions, 100),\n","    'Product': np.random.choice(products, 100),\n","    'Sales': np.random.randint(100, 1001, 100),\n","    'Quantity': np.random.randint(1, 11, 100)\n","})\n","\n","# Introduce NaN values\n","nan_indices = np.random.choice(df_sales.index, 5, replace=False)\n","df_sales.loc[nan_indices, 'Sales'] = np.nan\n","\n","nan_indices = np.random.choice(df_sales.index, 3, replace=False)\n","df_sales.loc[nan_indices, 'Quantity'] = np.nan\n","\n","# Your code for Task 2 here:\n","\n","\n","\n","\n","\n","\n","# Task 3: Indexing and Slicing in DataFrames\n","print(\"\\n--- Task 3: Indexing and Slicing in DataFrames ---\")\n","# Use 'df_sales' from Task 2.\n","# 3.1 Select only the 'Region' and 'Sales' columns. Store it in 'df3_1'.\n","df3_1 = df_sales[['Region', 'Sales']]\n","print(df3_1)\n","# 3.2 Select rows where 'Product' is 'Laptop'. Store it in 'df3_2'.\n","df3_2 = df_sales[df_sales['Product'] == 'Laptop']\n","print(df3_2)\n","# 3.3 Select rows where 'Region' is 'East' AND 'Sales' are greater than 500. Store it in 'df3_3'.\n","df3_3 = df_sales[(df_sales['Region'] == 'East') & (df_sales['Sales'] > 500)]\n","print(df3_3)\n","# 3.4 Select the 'Sales' value for the first entry where 'Product' is 'Monitor' (use .loc and .iloc). Store it in 'val3_4'.\n","val3_4 = df_sales.loc[df_sales['Product'] == 'Monitor', 'Sales'].iloc[0]\n","print(val3_4)\n","\n","# Your code for Task 3 here:\n","\n","\n","\n","# Task 4: Data Cleaning (Handling Missing Values)\n","print(\"\\n--- Task 4: Data Cleaning (Handling Missing Values) ---\")\n","# Use 'df_sales' from Task 2 (which should have NaNs)\n","\n","# 4.1 Check how many missing values are in each column. Store the result in 'missing_counts4_1'.\n","missing_counts4_1 = df_sales.isnull().sum()\n","print(missing_counts4_1)\n","# 4.2 Fill missing 'Sales' values with the mean of the 'Sales' column. Store the modified DataFrame in 'df4_2_filled'.\n","df4_2_filled = df_sales.copy()\n","df4_2_filled['Sales'].fillna(df4_2_filled['Sales'].mean(), inplace=True)\n","print(df4_2_filled)\n","# 4.3 Drop rows that have any missing values in 'df_sales'. Store the result in 'df4_3_dropped'.\n","df4_3_dropped = df_sales.dropna()\n","print(df4_3_dropped)\n","\n","# Your code for Task 4 here:\n","\n","\n","\n","# Task 5: Data Manipulation (Columns, Sorting, Grouping)\n","print(\"\\n--- Task 5: Data Manipulation (Columns, Sorting, Grouping) ---\")\n","# Use 'df_sales' (the original one with NaNs)\n","# 5.1 Create a new column 'Total_Revenue' which is 'Sales' * 'Quantity'.\n","#     (Be mindful of NaNs, the result should also be NaN where either Sales or Quantity is NaN).\n","df_sales['Total_Revenue'] = df_sales['Sales'] * df_sales['Quantity']\n","print(df_sales)\n","# 5.2 Sort 'df_sales' by 'Date' in ascending order, then by 'Sales' in descending order. Store it in 'df5_2_sorted'.\n","df5_2_sorted = df_sales.sort_values(by=['Date', 'Sales'], ascending=[True, False])\n","print(df5_2_sorted)\n","# 5.3 Group 'df_sales' by 'Region' and calculate the sum of 'Sales' and 'Quantity' for each region.\n","#     Store the result in 'df5_3_grouped_region'.\n","df5_3_grouped_region = df_sales.groupby('Region').agg({'Sales': 'sum', 'Quantity': 'sum'})\n","print(df5_3_grouped_region)\n","# 5.4 Group 'df_sales' by 'Product' and find the average 'Sales' for each product.\n","#     Store the result in 'df5_4_grouped_product'.\n","df5_4_grouped_product = df_sales.groupby('Product')['Sales'].mean()\n","print(df5_4_grouped_product)\n","\n","# Your code for Task 5 here:\n"]},{"cell_type":"code","source":[],"metadata":{"id":"jkbWTcIPA6di","executionInfo":{"status":"ok","timestamp":1751021591406,"user_tz":-330,"elapsed":2,"user":{"displayName":"Lokendra Sinha","userId":"01157800664172874909"}}},"execution_count":2,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1RG_ZCNemoTi69kMfG2StnQ-cEZP05FuT","timestamp":1751021356547}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}